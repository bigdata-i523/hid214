\documentclass[sigconf]{acmart}

\input{format/final}

\begin{document}
\title{Big Data and basketball}


\author{Junjie Lu}
% \orcid{1234-5678-9012}
\affiliation{%
  \institution{Indiana University Bloomington}
  \streetaddress{3322 John Hinkle Place}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{43017-6221}
}
\email{junjlu@iu.edu}

% The default list of authors is too long for headers}
% \renewcommand{\shortauthors}{B. Trovato et al.}


\begin{abstract}
When players shoot the ball, the movement trajectory could decide the shooting rate directly. Theoretical basis of kinematic mechanics can contribute to analyze the influence of rotation of basketball on air resistance. 
\end{abstract}

\keywords{i523, hid 214basketball, stats}


\maketitle

\section{Introduction}
These years people pay more and more attention to global sports competition. The importance of statistics has been changed too. Taking NBA as a example, approximately 50 years ago, people just recorded several kinds of basic statistics. People just used these data to analyze team's overall strength. As we all know there are many factors can determine the outcome of competition. More and more people anticipates for results for amount of money through betting companies. Traditional statistics could not make more contribution in predicting result of competition. People began to find more types of data and method to analysis and forecasting results of sports to improve predicting accuracy. But many machine learning methods had a bad performance on results prediction because of limitation of limited datasets. We will focus on the Maximum Entropy model which overcomes this limitation by making some assumption as unknown facts with little known facts. 
\section{The Body of The Paper}
\subsection{Analysis of alternation number}
Many factors would influence the alternation number:\\
\begin{enumerate}
    \item Defensive rebounds and offensive rebounds
    \item Turnovers and steals
    \item Violations and substitutions
\end{enumerate}
Alternation number can tell us something about alternation of attack side and defend side. But only point difference between two teams can tell us dynamics of the game from start to end. Here we just compare different point difference on final score. According the final result from 2011 to 2015:
\begin{enumerate}
    \item 65\% games is ended with a point difference below 10.
    \item 33\% games is ended with a point difference between 11 and 27.
    \item 2\% games is ended with a point difference more than 28.
\end{enumerate}
The distribution of alternation number in interval (1) is uniform. It is the reason of fierce matches. Players always pay more attention to their own defensive rebounds and getting avoid of being stolen. The distribution changes in interval (2). If the match lose its suspense too early, alternation number would be influenced. Players may be more relax so that players on another side would get more steals and offensive rebounds. Games in interval (3) is totally different, in fact we could hardly call them "match". Consequently, the distribution of alternation number changes radically. 

\subsection{Maximum entropy model}
Entropy is the expect value of information in message. We use it to measure uncertainty of random events. \cite{cite01} It can be written as:
\begin{equation*}
H(p) = -\sum_{i=1}^np_i\log_2 p_i
\end{equation*}
$p_i$ is random event's probability and $H(p)$ is entropy. The maximum entropy principle tells us we have to pick a set with maximum entropy and including all known information. \cite{cite02}. We can get the most uniform probability distribution in this way and may get the most accurate result prediction. And this most uniform probability distribution is Maximum entropy model. \cite{cite03} And condition entropy can be written as:\\
\begin{equation*}
H(p) = -\sum_{a,b}^n p(a)p(b|a)\log p(b|a)
\end{equation*}
The maximum entropy model works well with classification problems and is adaptable and flexible. Maximum entropy model has an advantage that it has its own internal mechanism which can deal with several features related with each other. This is the reason of its higher accuracy compared to other methods. 
\subsection{K-means clustering}
We always use clustering as unsupervised learning method to deal with unlabeled data. K-means clustering is a method of vector quantization and originally from signal processing.\cite{cite04} The standard algorithnm was first proposed by Stuart Lloyd in 1982.\cite{cite05} The central concepts of it was that portion n observations $\left\{x_1, x_2, · · ·, x_n\right\}$ into k clusters in which each observation belongs to the cluster with the nearest mean. \cite{cite06} \\
K-means steps are as follow:
\begin{enumerate}
    \item Set of centers is $\left\{v_1,v_2,...v_n\right\}$
    \item Set of data point is $\left\{x_1,x_2,...x_n\right\}$
    \item Number c is selected randomly as cluster center.
    \item Calculating data distance between data point and cluster center.
    \item Connect every data point to cluster center whom has minimum of distance.
    \item Repeat step 4.
    \item If there is still data point reassigned, repeat step 5, otherwise stop.
\end{enumerate}
As K-means clustering is one of the most effective methods to discretize features, so we used K-means clustering to discretize values of each feature.\cite{cite07}\\
\subsection{Prediction with Maximum Entropy model}
We will build Maximum Entropy model with basic features of match. We can regard the prediction as a classification when the outcome is one in two pools. 
We will consider about 11 common features to describe a game. 
\begin{enumerate}
    \item Field goal shoot
    \item Three point shoot
    \item Free throw shoot
    \item Offensive rebounds
    \item Assists
    \item Blocks
    \item Fouls
    \item Field goal attempt
    \item Defensive rebounds
    \item Steals
    \item Turnover
\end{enumerate}
There are so many feature functions we can choose here. It is a so significant step for perfect performance of the Maximum Entropy model. Hence we must choose a function which can match the model wonderfully and make full use of our features and data. \cite{cite08} We will use binary function here whose form is:\\
$$ f(a,b)=\left\{
\begin{aligned}
1, the result of match meets the data\\
0 , otherwise\\
\end{aligned}
\right.
$$\\
$b_i$ is the game output and $a_i$ represents features. There are X times $(x,y)$ occurs in the sample. There are totally N training data in the Set, we can get distribution of joint probability distribution $p (x, y)$ \cite{cite09}.
\begin{equation*}
p(a,b) = \frac{1}{N} * X
\end{equation*}\\
And the expectation is :
\begin{equation*}
E_p = \sum_{a,b}^n p(a,b)f(a,b)
\end{equation*}
\begin{equation*}
H(p) = -\sum_{a,b}^n p(a)p(b|a)\log p(b|a)
\end{equation*}
\subsection{Conclusion}
We pick 6 games and use their data as follow:
\begin{table*}[!hbp]
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\hline
Features & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) & (10) & (11) & Home team win \\
\hline
Match 1 & 35 & 20 & 23 & 11 & 33 & 8& 22 & 22 & 44 & 9 & 15 & 1\\
\hline
Match 2 & 43 & 34 & 32 & 9 & 22 & 2 & 21 & 27 & 32 & 8 & 17 & 1\\
\hline
Match 3 & 37 & 41 & 28 & 10 & 21 & 3 & 11 & 12 & 37 & 5 & 18 & 0\\
\hline
Match 4 & 22 & 23 & 21 & 11 & 17 & 1 & 19 & 32 & 29 & 11 & 13 & 1\\
\hline
Match 5 & 42 & 26 & 25 & 8 & 18 & 4 & 19 & 22 & 33 & 10 & 19 & 1\\
\hline
Match 6 & 32 & 23 & 32 & 9 & 18 & 5 & 22 & 22 & 36 & 8 & 20 & 1\\
\hline
\end{tabular}
\caption{Sample features}
\label{Sample features}
\end{table*} 
And we use the model to test past 6 years NBA matches and get the prediction accuracy as follow :
\begin{table*}[htb]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c}
         \hline
         Threshold & 2011-12 & 2012-13 & 2013-14 & 2014-15 & 2015-16 & 2016-17\\
         \hline
         0.5 & 76.3 & 69.1 & 69.3 & 67.5 & 64.6 & 68.5\\
         \hline
         0.6 & 77.1 & 75.9 & 79.3 & 78.5 & 79.5 & 76.4\\
         \hline 
         0.8 & 100.0 & 80.0 & 80.0 & 80.0 & 100.0 & 100.0\\
    \end{tabular}
    \caption{Prediction accuracy}
    \label{Prediction accuracy}
\end{table*}
\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 


\end{document}
